# Chathistory Federation: Storage, Advertisement & Forwarding

## Status: IMPLEMENTATION IN PROGRESS

### Implementation Progress

| Phase | Status | Notes |
|-------|--------|-------|
| Phase 0 - Storage/CAP Decoupling | âœ… Complete | Added FEAT_CHATHISTORY_STORE, updated all storage paths |
| Phase 1 - Infrastructure | âœ… Complete | Data structures, CH A parser, helper functions |
| Phase 2 - Advertisement Sending | âœ… Complete | CH A S now checks STORE flag correctly |
| Phase 3 - Advertisement-Based Routing | âœ… Complete | Query routing filters by CH A S |
| Phase 4 - Write Forwarding (CH W) | âœ… Complete | CH W/WB with chunking, deduplication, forwarding hook |
| Phase 5 - Registered Channel Storage | âœ… Complete | Included in Phase 4 process_write_forward() |
| Phase 6 - Storage Management | âœ… Complete | Watermarks, eviction, graceful degradation |
| Phase 7 - Refinements | ğŸ”² Future | |

### Pre-Implementation Investigation

- âœ… **Msgid propagation verified**: Msgids ARE preserved through all P10 relay paths
  - First hop generates msgid (local user origin)
  - Subsequent hops preserve via `cli_s2s_msgid()` buffer
  - Deduplication strategy confirmed viable

---

## Critical Architectural Insight: Storage vs. CAP Decoupling

**Problem:** The current implementation conflates three separate concerns under `FEAT_CAP_draft_chathistory`:
1. CAP advertisement to clients (`draft/chathistory`)
2. Local storage of messages to LMDB
3. Query handling (CHATHISTORY command)

This means a server cannot advertise chathistory capability to clients while forwarding queries to storage servers elsewhere on the network.

### Required Decoupling

**Two independent feature flags:**

| Feature | Purpose | Default |
|---------|---------|---------|
| `FEAT_CAP_draft_chathistory` | Advertise CAP, handle CHATHISTORY commands | Existing |
| `FEAT_CHATHISTORY_STORE` | Actually write messages to local LMDB | **NEW** |

**Server roles enabled by decoupling:**

| Server Type | CAP | STORE | Behavior |
|-------------|-----|-------|----------|
| **Storage Server** | âœ… | âœ… | Stores locally, answers queries, sends CH A S |
| **Relay Server** | âœ… | âŒ | Forwards writes (CH W), forwards queries to STORE servers, no CH A S |
| **Legacy Server** | âŒ | âŒ | No chathistory participation |

**Key behaviors:**
- **Relay servers** can still advertise `draft/chathistory` CAP to clients
- Client CHATHISTORY queries are forwarded to STORE servers via federation
- CH W writes are forwarded to STORE servers for persistence
- CH A S is ONLY sent by servers with `FEAT_CHATHISTORY_STORE` enabled

### X3 Role in Federation

X3 participates in chathistory federation via **HistServ**, a bot interface for legacy clients:

| Aspect | X3 Behavior |
|--------|-------------|
| **Storage** | âŒ Does NOT store messages |
| **CH A S** | âŒ Does NOT send (no storage capability) |
| **CH A parsing** | âœ… Understands for routing awareness |
| **HistServ** | âœ… Bot interface for clients without `draft/chathistory` CAP |
| **CH W (channels)** | âŒ Does NOT send (IRCd handles forwarding) |
| **CH W (PMs)** | N/A - Service bots don't consent to PM history |

**HistServ function:** X3 provides a services bot (HistServ) that users can message to request channel history. X3 natively speaks the P10 chathistory protocol - it sends `CH Q` queries and receives `CH R` responses, then formats results as NOTICE/PRIVMSG replies in a bot-like manner.

This is NOT relaying - X3 is a P10 chathistory client that presents results through a bot interface.

**Service Bot PM History:** PMs to/from service bots (AuthServ, ChanServ, HistServ, etc.) are excluded from chathistory storage via the consent system. Service bots do not consent to PM history, so:
- No storage of user commands (which may contain passwords)
- No storage of service responses
- No CH W forwarding needed for service bot PMs
- Nefarious handles all CH W logic; X3 never needs to send CH W

**No code changes needed in X3** for Phase 0-2. X3 already:
- Doesn't store chathistory locally
- Speaks P10 chathistory protocol natively (CH Q/CH R)
- Service bots have no PM history consent (by design)
- Could benefit from CH A awareness for smarter query routing (future)

---

This plan addresses comprehensive chathistory federation including:
- **Hybrid Storage Model**: Registered channels stored everywhere, unregistered use forwarding
- **Presence Advertisement (CH A)**: Servers advertise what history they have
- **Write Forwarding (CH W)**: Non-storing servers forward to storage servers
- **Storage Management**: Eviction, watermarks, graceful degradation

---

## Table of Contents

1. [Executive Summary](#executive-summary)
   - [Hybrid Storage Model](#hybrid-storage-model)
   - [Critical P10 Relay Gap](#critical-p10-relay-gap)
2. [Approach A: Core Relay Modification](#approach-a-core-relay-modification-for-registered-channels)
3. [Approach B: Write Forwarding](#approach-b-write-forwarding-ch-w)
4. [Protocol Design (CH A)](#protocol-design)
5. [Write Forwarding Details (CH W)](#write-forwarding-ch-w)
6. [Storage Management](#storage-management)
7. [Query Routing Logic](#query-routing-logic)
8. [Implementation Plan](#implementation-plan)
9. [Configuration Reference](#configuration-reference)
10. [Security Considerations](#security-considerations)
11. [Edge Cases](#edge-cases)
12. [Recommendation: Approach A vs. B](#recommendation-approach-a-vs-b)
13. [Open Questions](#open-questions)
14. [Success Criteria](#success-criteria)

---

## Executive Summary

This plan explores **proactive chathistory presence advertisement** - a P10 protocol extension where servers advertise what chathistory they have available, enabling intelligent federation routing and avoiding unnecessary queries to servers without relevant history.

### Problem Statement

Currently, when a CHATHISTORY query arrives and local history is insufficient, the server:
1. Queries ALL connected (non-U-lined) servers via `CH Q` (federation query)
2. Waits up to 5 seconds (FEAT_CHATHISTORY_TIMEOUT) for responses
3. Aggregates results and returns to client

This has issues:
- **Latency**: Even if only one server has history, we wait for all to respond
- **Redundant traffic**: Servers with no history still receive and process queries
- **Timeout dependency**: We can't know if a server has nothing or is just slow

### Goals

1. Reduce unnecessary federation traffic
2. Enable faster CHATHISTORY responses by targeting only relevant servers
3. Maintain correctness (never miss history that exists)
4. Scale to networks with many servers and channels
5. **Eliminate storage gaps** via hybrid approach (requires Approach A or B):
   - **Registered channels**: Stored on all STORE servers that receive them (+r mode)
   - **Delivery**: Non-STORE servers must forward messages to STORE servers (see [Critical P10 Relay Gap](#critical-p10-relay-gap))

### Design Layers

| Layer | Scope | Purpose | Overhead |
|-------|-------|---------|----------|
| **Layer 0** | Server | "I store history with N-day retention" | O(1) per server |
| **Layer 1** | Channel | "I have history for channels X, Y, Z" | O(channels) |
| **Layer 1b** | User/DM | "I have DM history for users A, B, C" | O(users) |

**Foundation**: Layer 0 (storage capability + retention) is required. Higher layers are optional refinements.

### Hybrid Storage Model

The key insight is **registered channel storage** combined with **write forwarding** to eliminate gaps.

**âš ï¸ Important:** This flowchart shows what happens *once messages arrive at a server*. See [Critical P10 Relay Gap](#critical-p10-relay-gap) for the crucial issue of HOW messages reach servers in the first place.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      STORAGE DECISION FLOWCHART                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Message arrives at server                                             â”‚
â”‚          â”‚                                                              â”‚
â”‚          â–¼                                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     NO                                               â”‚
â”‚   â”‚ Am I a STORE â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚   server?    â”‚                                       â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚              â”‚
â”‚          â”‚ YES                                           â”‚              â”‚
â”‚          â–¼                                               â–¼              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     YES     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Channel has  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   STORE IT   â”‚   â”‚ Is channel   â”‚     â”‚
â”‚   â”‚ local users? â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ registered?  â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          â”‚ NO                                            â”‚              â”‚
â”‚          â–¼                                               â”‚ NO           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     YES                               â–¼              â”‚
â”‚   â”‚ Is channel   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ registered?  â”‚             â”‚   STORE IT   â”‚   â”‚ FORWARD via  â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  (+r policy) â”‚   â”‚    CH W      â”‚     â”‚
â”‚          â”‚ NO                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ (Approach B) â”‚     â”‚
â”‚          â–¼                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚   â”‚  Don't store â”‚                                                      â”‚
â”‚   â”‚ (no interest)â”‚                                                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Registered channel policy**: STORE servers store messages for channels with +r mode, regardless of local user presence.

**Non-STORE behavior**: Forward ALL messages to nearest STORE via CH W (Approach B). STORE servers decide what to keep.

### Critical P10 Relay Gap

âš ï¸ **The flowchart above has a critical flaw that must be addressed.**

The current P10 relay implementation (`sendcmdto_channel_butone()` in send.c) only sends messages to servers that have users in the channel:

```c
// Current P10 relay logic (simplified)
for (member = to->members; member; member = member->next_member) {
  if (MyConnect(member->user))    // Skip local users
    continue;
  send_buffer(member->user, ...); // Send to server via this user's connection
}
```

**Problem:** If a registered channel has users ONLY on non-STORE servers:
- P10 relay sends to servers with users â†’ non-STORE servers only
- STORE servers never receive the message (no users in channel)
- Even with +r triggering storage, STORE servers have nothing to store

**Example:**
```
#collab channel: users on us-w (no STORE) and au1 (no STORE) only

User@us-w: PRIVMSG #collab :hello
       â†“
P10 relays to au1 (has user) - via hub-au, hub-asia
       â†“
us-e (STORE) NOT in relay path (no users)
asia1 (STORE) NOT in relay path (no users)
       â†“
Message delivered but NEVER reaches any STORE server
```

**Two approaches to solve this (both are P10 changes):**

| Approach | Where in P10 | What Changes | Impact Scope |
|----------|--------------|--------------|--------------|
| **A: Core Relay Modification** | `sendcmdto_channel_*()` | Delivery routing | All channel messages |
| **B: Parallel Storage Path (CH W)** | New command handler | Adds forwarding layer | Storage only |

**Key difference:** Approach A modifies how messages are *delivered*; Approach B adds a separate path for *storage* that doesn't affect delivery.

See [Approach A: Core Relay Modification](#approach-a-core-relay-modification-for-registered-channels) and [Approach B: Write Forwarding](#write-forwarding-ch-w) sections for detailed analysis.

---

## Approach A: Core Relay Modification for Registered Channels

### Concept

Modify `sendcmdto_channel_butone()` and `sendcmdto_channel_servers_butone()` to also send messages for registered channels (+r) to at least one STORE server, even if that server has no users in the channel.

### Implementation Sketch

```c
void sendcmdto_channel_butone(struct Client *from, const char *cmd,
                              const char *tok, struct Channel *to,
                              struct Client *one, unsigned int skip,
                              unsigned char prefix, const char *pattern, ...)
{
  // ... existing member iteration for delivery ...

  /* NEW: For registered channels, ensure STORE servers receive the message */
  if (IsRegisteredChannel(to) && !already_sent_to_store_server) {
    struct Client *store_server = find_nearest_store_server();
    if (store_server && cli_sentalong(store_server) != sentalong_marker) {
      cli_sentalong(store_server) = sentalong_marker;
      send_buffer(store_server, serv_mb, 0);
    }
  }
}
```

### Considerations

#### 1. Which Server to Send To?

Options:
- **Nearest STORE server** - Minimize hops, but concentrates load on one server
- **All STORE servers** - Maximum redundancy, but O(STORE servers) extra traffic
- **Primary STORE server** - Designated archive, single point of failure

**Recommendation:** Send to nearest STORE server. If redundancy needed, that server can fan-out or use replication.

#### 2. Message Format

The message arrives at the STORE server exactly like any P10 relay - no special handling needed. The STORE server's existing code sees:
```
AB P #channel :hello
```
...with full tags (msgid, time, etc.). It just needs to decide to store it despite having no local users.

#### 3. STORE Server Storage Decision

STORE servers need to know this is a "storage relay" vs. normal relay:

**Option A: Implicit (mode-based)**
```c
// On STORE server receiving P/N for channel
if (IsRegisteredChannel(chptr) || channel_has_local_users(chptr)) {
  store_message(...);
}
```

**Option B: Explicit (flag in P10)**
```
AB P #channel :hello    â† Normal relay, STORE only if local users
AB P! #channel :hello   â† Storage relay, STORE regardless
```

**Recommendation:** Option A (implicit) - simpler, no protocol change at receiving end.

#### 4. Avoiding Loops

If multiple non-STORE servers each send to a STORE server, or if STORE servers relay to each other, we could get duplicates or loops.

**Safeguards:**
- STORE servers do NOT further relay storage-only messages
- Only the originating server's direct uplink sends to STORE (not all servers in path)
- Use `sentalong_marker` to prevent duplicate sends within same message propagation

#### 5. Hub Topology Interaction

In hub-spoke topology:
```
Leaf1(no-store) -- Hub(no-store) -- Leaf2(STORE)
```

If user on Leaf1 sends to #registered:
- Leaf1 â†’ Hub (normal relay path)
- Hub â†’ Leaf2 (needs to send for storage, even if no users)

**Question:** Does Hub know to send to Leaf2?

With current implementation, Hub only relays to servers with channel users. So Hub would need the same modification.

**This is the key challenge:** Every server in the path needs to participate, not just the originating server.

### Risks

| Risk | Severity | Mitigation |
|------|----------|------------|
| Increased traffic | Medium | Only registered channels affected |
| Message loops | High | Use sentalong + storage-only flag |
| Hub routing complexity | Medium | Each server must know STORE topology |
| Breaking non-storage servers | Low | Graceful ignore of extra messages |
| Subtle delivery bugs | High | Extensive testing required |

### When to Choose This Approach

âœ… **Choose A if:**
- You want messages to arrive "naturally" at STORE servers
- You need minimal protocol surface area
- Network topology is simple (few hops between any server and a STORE)

âŒ **Avoid A if:**
- Complex hub topology where relay logic is delicate
- You want storage completely decoupled from delivery
- Risk tolerance for delivery bugs is low

---

## Approach B: Write Forwarding (CH W)

This approach adds a parallel path for storage that doesn't modify core message delivery. See [Write Forwarding](#write-forwarding-ch-w) section below for full details.

**Key advantages over Approach A:**
- Core relay unchanged - delivery continues to work exactly as before
- Storage is an independent concern - failures don't affect delivery
- Easier to test - new code path, not modification of existing
- Cleaner rollout - can enable/disable per-server

**Key disadvantages:**
- Additional protocol command to implement
- Extra message hop (non-STORE â†’ STORE)
- Deduplication needed at STORE servers

---

## Protocol Design

### P10 Command: CH A (Chathistory Advertisement)

Sent by a server to advertise its chathistory storage capabilities.

### Layer 0: Storage Capability

**Required for any server that stores chathistory.**

#### Storage Advertisement (at BURST)

```
<server> CH A S <retention_days>
```
- `S` = Storage capability advertisement
- `<retention_days>` = Server's CHATHISTORY_RETENTION setting in days (0 = unlimited)
- Absence of this message = "I don't store history, don't query me"

Example:
```
AX CH A S 7
```
Server AX stores chathistory with 7-day retention.

#### Retention Update (on REHASH)

```
<server> CH A R <retention_days>
```
- `R` = Retention update only
- Sent when retention policy changes via REHASH

#### Route Advertisement Model

The `CH A S <days>` message represents **reachable retention**, not just local storage:
- A **storing server** sends its own retention
- A **non-storing hub** sends `max(children's advertised retentions)`
- A server with **no storage and no storing children** sends nothing

This enables cost-optimized architectures where only a few servers store history while the whole network benefits.

**Propagation Rules:**

| Event | Action |
|-------|--------|
| Server link (BURST) | Send `CH A S <max_reachable>` |
| Child link | If max increased, send `CH A R <new_max>` to peers |
| Child SQUIT | If max decreased, send `CH A R <new_max>` to peers |
| REHASH | If local retention changed, recalculate and send `CH A R` |

**Example topology:**
```
Leaf1(7d) --- Hub(0) --- Hub2(0) --- Leaf2(14d)
                |
            Leaf3(7d)
```

Result: Every server knows 14 days of history is reachable somewhere.

---

### Layer 1: Channel Presence

**Optional extension for channel-specific routing.**

#### Full Channel Sync

```
<server> CH A F :<channel1> <channel2> <channel3> ...
```
- `F` = Full channel set (replaces previous)
- May be split across multiple messages for large lists
- Only sent by servers that have already sent `CH A S`

#### Incremental Updates

```
<server> CH A + :<channel>    # Add channel
<server> CH A - :<channel>    # Remove channel (optional, rarely used)
```

**When to send incremental add:**
- First message written to a new channel

**When to send incremental remove:**
- When certain channel history is empty/expired (optional - false positives are acceptable)

---

### Layer 1b: User/DM Presence

**Optional extension for DM history routing.**

DM history is stored by **nick** (as `nick1:nick2` sorted pairs), not by account. This creates challenges due to nick volatility.

#### Full User Sync

```
<server> CH A U :<nick1> <nick2> <nick3> ...
```
- `U` = User/nick set (replaces previous)
- Nicks for which this server has DM history (as sender OR recipient)

#### Incremental Add

```
<server> CH A u :<nick>
```
- `u` = Add nick to DM advertisement set
- Sent when first DM involving this nick is stored

#### Account-Enhanced Approach (Future)

Since messages already store the sender's account when logged in, we could leverage this:

```
<server> CH A a :<account1> <account2> ...    # Accounts with DM history
```

**Coverage matrix:**

| User Type | Nick Advertised | Account Advertised | Queryable By |
|-----------|-----------------|-------------------|--------------|
| Unregistered | âœ… | âŒ | Nick only |
| Registered (logged in) | âœ… | âœ… | Nick or account |
| Registered (not logged in) | âœ… | âŒ | Nick only |

#### Recommendation: Defer Layer 1b

Given the complexity of nick volatility, the pragmatic initial approach:
- **Use Layer 0 only for DM history**: Query all storing servers (filtered by retention)
- **Defer Layer 1b**: Implement as future optimization
- **Rationale**: The number of storing servers is typically small

---

## Write Forwarding (CH W)

### Problem: Storage Gaps

The advertisement system tells servers **where history is stored** but doesn't solve **storage gaps** - regions where no server stores history.

Consider this topology:
```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚           CORE BACKBONE             â”‚
                                    â”‚                                     â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  hub-us  â”‚â”€â”€â”€â”€â”‚ hub-eu   â”‚â”€â”€â”€â”€â”‚ hub-asia â”‚â”€â”€â”€â”€â”‚ hub-au   â”‚â”€â”€â”€â”€â”‚ hub-sa   â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚               â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
â”‚us-e  â”‚us-w  â”‚ â”‚eu-w  â”‚eu-e  â”‚ â”‚asia1 â”‚asia2 â”‚ â”‚ au1  â”‚ au2  â”‚ â”‚ sa1  â”‚ sa2  â”‚
â”‚STORE â”‚      â”‚ â”‚STORE â”‚      â”‚ â”‚STORE â”‚      â”‚ â”‚      â”‚      â”‚ â”‚STORE â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

**Australia has no storage server.** Channels with users only on au1/au2 have messages witnessed but never stored.

#### Critical Gap: Cross-Region Non-Storage Channels

Even worse, consider a channel `#us-au-collab` with users **only** on us-w (no STORE) and au1 (no STORE):

```
User@us-w â†’ PRIVMSG #us-au-collab :hello
         â†“
Relayed to au1 (has channel user)
         â†“
Neither us-w nor au1 stores â†’ MESSAGE LOST
```

The current "store if local users" model fails here because:
- us-e (STORE) has no users in #us-au-collab â†’ doesn't store
- All other STORE servers similarly have no local users â†’ don't store
- Message is delivered but **never persisted anywhere**

### Hybrid Solution: Registration + Write Forwarding

To eliminate storage gaps, we combine **registration-based storage** with **write forwarding**:

| Channel Type | Storage Mechanism | Trigger |
|--------------|-------------------|---------|
| **Registered** | All STORE servers store ALL messages | Channel mode +r (ChanServ) |
| **Unregistered** | Write forwarding to nearest STORE | Non-storing server forwards |

#### Registered Channel Storage Policy

**Key insight:** ChanServ joins every registered channel, but it's a remote user from the services server, not a local user on storage-capable leafs. We can use **channel registration status** (+r mode) instead of ChanServ's presence.

âš ï¸ **Important:** This policy only works if messages actually REACH the STORE servers. See [Critical P10 Relay Gap](#critical-p10-relay-gap) - either Approach A or B is required.

**Storage policy change (STORE server side):**
```c
// OLD: Store only if we have local users
int should_store = channel_has_local_users(chptr);

// NEW: Store if local users OR channel is registered
int should_store = channel_has_local_users(chptr) || IsRegisteredChannel(chptr);
```

**Benefits (once messages reach STORE servers):**
- Registered channels are always stored on STORE servers that receive them
- Federation queries find history
- Aligns with user expectation that "registered = persistent"

**How it works (with Approach A or B):**
```
User@us-w â†’ PRIVMSG #us-au-collab :hello (registered channel)
         â†“
[Approach A]: Core relay sends to STORE server despite no local users
[Approach B]: us-w forwards via CH W to nearest STORE server
         â†“
STORE server sees +r mode â†’ stores message
         â†“
History available via federation query
```

**Without either approach:**
```
User@us-w â†’ PRIVMSG #us-au-collab :hello (registered channel)
         â†“
P10 relays only to au1 (has users)
         â†“
NO STORE server receives the message â†’ NOTHING STORED
```

#### How Messages Reach STORE Servers

With Approach B, non-STORE servers forward ALL channel messages via CH W. The STORE server then applies the storage policy (store if registered OR has local users).

For unregistered channels in storage gaps, this means:
- If STORE server has local users â†’ stores naturally
- If no STORE server has users â†’ message forwarded but not stored (acceptable for ad-hoc channels)

### Solution: Write Forwarding

Non-storing servers forward writes to the nearest storing server:

```
User on au1 â†’ PRIVMSG #au-only :hello

au1: "I don't store, but asia1 does (via hub-asia)"
au1 â†’ hub-au â†’ hub-asia â†’ asia1: CH W #au-only <msgid> <ts> <sender> :hello
asia1: stores the message
```

### Protocol: CH W / CH WB (Write Forward)

P10 line limit is 512 bytes. After headers (~100 bytes), ~400 bytes safe for content.
Multiline messages can be up to 4096 bytes, requiring chunked base64 encoding.

**CH W - Plain text (content â‰¤ 400 bytes, no newlines):**
```
<server> CH W <target> <msgid> <timestamp> <sender> <account|*> <type> :<text>
```

**CH WB - Base64 encoded (for large/multiline content):**
```
First/full:  <server> CH WB <target> <msgid> <ts> <sender> <account> <type> [+] :<b64>
Continue:    <server> CH WB <target> <msgid> [+] :<b64>
Final:       <server> CH WB <target> <msgid> :<b64>
```
The `+` marker indicates more chunks are coming.

**Parameters:**
- `<target>` - Channel name or nick (for DMs)
- `<msgid>` - Message ID (for deduplication)
- `<timestamp>` - Unix epoch timestamp with milliseconds (e.g., 1736856000.123)
- `<sender>` - Full sender mask (nick!user@host)
- `<account|*>` - Sender's account or `*` if not logged in
- `<type>` - Message type: `P` (PRIVMSG), `N` (NOTICE), `T` (TAGMSG)
- `<text>` - Message content (plain or base64 encoded)

**Examples:**
```
B4 CH W #channel yH5kM9x2 1736856000.123 alice!alice@host alice P :Hello!
B4 CH WB #channel abc123 1736856000.123 alice!alice@host alice P + :SGVsbG8gV29y...
B4 CH WB #channel abc123 + :bGQgdGhpcyBp...
B4 CH WB #channel abc123 :cyBtdWx0aWxpbmU=
```

### Routing

Forward to nearest server with storage advertisement:

```c
struct Client *nearest_storage = NULL;
int min_hops = INT_MAX;

for (struct DLink *lp = cli_serv(&me)->down; lp; lp = lp->next) {
  struct Client *server = lp->value.cptr;

  if (!has_storage_advertisement(server))
    continue;

  int hops = storage_hops(server);
  if (hops < min_hops) {
    min_hops = hops;
    nearest_storage = server;
  }
}
```

### Trigger Conditions

With Approach B (write forwarding), **non-STORE servers forward ALL channel messages** regardless of registration status. The STORE server decides what to store.

**Forwarding Logic (non-STORE server):**
```c
void maybe_forward_history(struct Channel *chptr, struct Client *sptr,
                          const char *msgid, const char *text)
{
  /* I'm a storage server - no forwarding needed */
  if (feature_bool(FEAT_CAP_draft_chathistory))
    return;

  /* No reachable storage anywhere - can't forward */
  if (!has_reachable_storage())
    return;

  /* Forward to nearest STORE server - let THEM decide what to store */
  forward_history_write(chptr, sptr, msgid, text);
}
```

#### STORE Server Storage Decision (CH W Handler)
```c
int ms_chathistory_write(struct Client *cptr, struct Client *sptr,
                         int parc, char *parv[])
{
  struct Channel *chptr = FindChannel(target);
  if (!chptr) return 0;  /* Channel doesn't exist here */

  /* Deduplication check */
  if (history_has_msgid(target, msgid))
    return 0;

  /* Storage decision: registered OR has local users */
  if (IsRegisteredChannel(chptr) || channel_has_local_users(chptr)) {
    history_store_message(msgid, timestamp, target, sender, account, type, text);
  }

  return 0;
}
```

**When forwarding happens (non-STORE server):**
1. Server does NOT have CHATHISTORY enabled locally
2. Reachable storage exists somewhere on the network
3. Message is for a channel (PRIVMSG, NOTICE, TAGMSG)

**When STORE server stores (receiving CH W):**
- **Registered channel (+r):** Always store
- **Unregistered with local users:** Store (natural interest)
- **Unregistered without local users:** Don't store (no interest)

**Key insight:** The non-STORE server doesn't need to know whether the channel is registered or whether any STORE server has users. It just forwards. The STORE server makes the storage decision based on its local state.

**Edge case - Channel structure existence:**
When ChanServ joins a registered channel, that JOIN propagates to all servers, creating the channel structure network-wide. However, for unregistered channels that exist only on non-STORE servers, the STORE server may not have a channel structure at all.

Solution: CH W handler creates channel structure if needed (for storage purposes only):
```c
struct Channel *chptr = FindChannel(target);
if (!chptr) {
  /* Channel doesn't exist locally - create transient structure for storage */
  chptr = create_storage_channel(target);  /* Lightweight, no user membership */
}
```

### Deduplication

Write forwarding may cause duplicate storage:
- Naturally stored on servers with local channel users
- Forwarded by non-storing servers

**Solution:** Dedup by `msgid`.

**Critical assumption:** Msgids are generated **once** at the originating server and propagate unchanged through all paths:

```
User@au1 â†’ PRIVMSG #channel :hello
           â†“
au1 generates msgid "au1-1736856000-x7f2"
           â†“
Relays to all servers with same msgid in tags
           â†“
CH W also carries same msgid (NOT a new one)
```

**Requirements for dedup to work:**
1. Originating server always generates msgid (Nefarious does this)
2. P10 relay preserves message tags including msgid
3. CH W **must** use the original msgid from the message, never generate a new one
4. Storing servers check `history_has_msgid()` before inserting

**If msgids are not preserved:** Deduplication fails. Messages could be stored multiple times with different IDs. This is a correctness bug, not a design flaw - the fix is to ensure msgid preservation, not change dedup strategy.

### Reception Handling

See [STORE Server Storage Decision](#store-server-storage-decision-ch-w-handler) above for the full handler logic. Key points:
- Validate CHATHISTORY is enabled locally
- Create lightweight channel structure if needed
- Dedup by msgid
- Store if registered OR has local users
- Do NOT propagate CH W further (point-to-point)

### Failure Modes

| Scenario | Behavior |
|----------|----------|
| Storage unreachable | Message delivered to users, history lost (acceptable) |
| Storage at capacity | Message not stored, could return `CH W E` error |
| Network partition | Each side forwards to reachable storage; gaps possible |

---

## Storage Management

### Problem: Storage Full

LMDB databases have fixed maximum size (`mapsize`). When storage approaches capacity:
- **Current behavior**: Write fails silently
- **User expectation**: Older history should be shed for new messages
- **Design goal**: Automatic eviction with graceful degradation

### Eviction Strategy: Hybrid

Combine proactive and reactive eviction:

```c
/* Background - every 5 minutes */
void history_maintenance_tick(void)
{
  if (history_db_utilization() > HIGH_WATERMARK) {  /* 0.85 */
    history_evict_to_target(LOW_WATERMARK);         /* 0.75 */
  }
}

/* Inline - on write failure */
int history_store_message(...)
{
  int result = lmdb_put(...);

  if (result == MDB_MAP_FULL) {
    history_evict_emergency();
    result = lmdb_put(...);
  }

  return result;
}
```

### Eviction Order

Two-dimensional priority: **type first, then age**.

| Pass | What | Rationale |
|------|------|-----------|
| 1 | Expired events | JOIN/PART/QUIT beyond retention - lowest value |
| 2 | Expired messages | PRIVMSG/NOTICE beyond retention |
| 3 | Near-expiry events | Events >50% of retention age |
| 4 | Near-expiry messages | Messages >75% of retention age |
| 5 | Oldest events | Global oldest events |
| 6 | Oldest messages | Last resort |

**Why events before messages:**
- Events are more numerous (every join/part/quit)
- Events have less historical value - users want conversations
- Current channel state is reconstructible; old events rarely needed

```c
typedef enum {
  TYPE_MESSAGE,  /* PRIVMSG, NOTICE - high value */
  TYPE_EVENT     /* JOIN, PART, QUIT, NICK, MODE, KICK, TOPIC - low value */
} HistoryItemType;
```

### Graceful Degradation

| Level | Utilization | Behavior |
|-------|-------------|----------|
| NORMAL | <90% | Normal operation |
| WARNING | 90-95% | Eviction active, oper notification |
| CRITICAL | 95-99% | Reduced retention, aggressive eviction |
| SUSPENDED | >99% | No new writes, serve existing data only |

```c
typedef enum {
  STORAGE_NORMAL,
  STORAGE_WARNING,
  STORAGE_CRITICAL,
  STORAGE_SUSPENDED
} StorageState;
```

### STATS Command Extension

```
/stats H
:server 250 nick :Chathistory Storage:
:server 250 nick :  Size: 856MB / 1024MB (83.6%)
:server 250 nick :  State: NORMAL
:server 250 nick :  Retention: 7 days
:server 250 nick :  Messages: 1,234,567
:server 250 nick :  Channels: 4,521
:server 250 nick :  Last eviction: 2026-01-14 08:30:00 (52 messages)
```

### Edge Case: Expired Forwarded Messages

Reject messages that are already past retention:

```c
time_t msg_time = (time_t)strtoul(timestamp, NULL, 10);
time_t retention_cutoff = CurrentTime - (retention_days * 86400);

if (msg_time < retention_cutoff) {
  /* Don't bother storing - would be evicted immediately */
  return 0;
}
```

---

## Query Routing Logic

Apply checks in order of cost:

```c
static void route_fed_query(const char *target, time_t query_time, ...)
{
  time_t now = CurrentTime;

  for (struct DLink *lp = cli_serv(&me)->down; lp; lp = lp->next) {
    struct Client *server = lp->value.cptr;

    /* Skip services */
    if (is_ulined_server(server))
      continue;

    /* Layer 0: Storage capability */
    if (!has_storage_advertisement(server))
      continue;  /* Doesn't store history */

    /* Layer 0: Retention floor */
    int retention_days = server_retention_days(server);
    if (retention_days > 0) {
      time_t oldest_possible = now - (retention_days * 86400);
      if (query_time < oldest_possible)
        continue;  /* Query predates retention window */
    }

    /* Layer 1: Channel presence (optional) */
    if (has_channel_advertisement(server)) {
      if (!server_advertises_channel(server, target))
        continue;  /* Explicitly doesn't have this channel */
    }

    /* Query this server */
    sendcmdto_one(&me, CMD_CHATHISTORY, server, "Q %s ...", target);
    sent_count++;
  }
}
```

### Data Structures

```c
struct ChathistoryAd {
  int has_advertisement;      /* Received any CH A? */
  int retention_days;         /* Retention policy (0 = unlimited) */
  struct HashTable *channels; /* Set of channel names (lowercase) */
  struct HashTable *nicks;    /* Set of nicks with DM history */
  time_t last_full_sync;      /* When received CH A F */
  time_t last_update;         /* When received any CH A */
};

static struct ChathistoryAd *server_ads[4096];  /* MAXSERVERS */
```

---

## Implementation Plan

### Phase 0: Storage/CAP Decoupling (Required First)

**Goal:** Separate the "storage" concern from the "CAP advertisement" concern.

#### Step 1: Add new feature flag (`ircd_features.def`)

```c
/* Chathistory storage - separate from CAP advertisement */
F_B(CHATHISTORY_STORE, 0, 1),  /* TRUE = store messages locally, FALSE = relay-only */
```

**Default:** TRUE for backward compatibility with existing deployments.

#### Step 2: Update storage write path (`chathistory.c`)

Change storage writes to check `FEAT_CHATHISTORY_STORE`:

```c
/* Before: */
if (!feature_bool(FEAT_CAP_draft_chathistory))
  return;

/* After: */
if (!feature_bool(FEAT_CHATHISTORY_STORE))
  return;
```

Locations to update:
- `chathistory_privmsg()` - PRIVMSG storage
- `chathistory_notice()` - NOTICE storage
- `chathistory_tagmsg()` - TAGMSG storage
- `chathistory_join()` - JOIN event storage
- `chathistory_part()` - PART event storage
- `chathistory_quit()` - QUIT event storage
- `chathistory_nick()` - NICK event storage
- `chathistory_kick()` - KICK event storage
- `chathistory_topic()` - TOPIC event storage
- `chathistory_mode()` - MODE event storage

#### Step 3: Update query handling (`m_chathistory.c`)

Query handling should check `FEAT_CAP_draft_chathistory` (CAP), not STORE:

```c
/* Client queries: CAP must be enabled */
if (!feature_bool(FEAT_CAP_draft_chathistory))
  return send_reply(sptr, ERR_UNKNOWNCOMMAND, "CHATHISTORY");
```

Local queries (from connected clients) should:
1. Check local storage if `FEAT_CHATHISTORY_STORE` is enabled
2. Forward to federation regardless (unless local results are complete)

#### Step 4: Update CH A S sending (`m_endburst.c`)

Change from checking CAP to checking STORE:

```c
/* Before: */
if (feature_bool(FEAT_CAP_draft_chathistory)) {
  int retention = feature_int(FEAT_CHATHISTORY_RETENTION);
  sendcmdto_one(&me, CMD_CHATHISTORY, sptr, "A S %d", retention);
}

/* After: */
if (feature_bool(FEAT_CHATHISTORY_STORE)) {
  int retention = feature_int(FEAT_CHATHISTORY_RETENTION);
  sendcmdto_one(&me, CMD_CHATHISTORY, sptr, "A S %d", retention);
}
```

**Only STORE servers should advertise storage capability.**

#### Step 5: Update documentation

- `FEATURE_FLAGS_CONFIG.md` - document new flag
- `data/ircd.conf` templates - show both flags

#### Verification

Test matrix:

| CAP | STORE | Expected Behavior |
|-----|-------|-------------------|
| âœ… | âœ… | Full chathistory (current default) |
| âœ… | âŒ | CAP advertised, queries forwarded, no local storage, no CH A S |
| âŒ | âœ… | Invalid config - warn at startup, treat as âŒ/âŒ |
| âŒ | âŒ | No chathistory participation |

**Test commands:**
```bash
# Server with STORE disabled should NOT store messages
# Server with STORE disabled should NOT send CH A S at BURST
# Server with CAP enabled but STORE disabled should still respond to CHATHISTORY queries
```

---

### Phase 1: Infrastructure (No Behavior Change) âœ… COMPLETE

1. Add `struct ChathistoryAd` data structures
2. Add `CH A` message parser (accept and store, don't use yet)
3. Add helper functions: `has_chathistory_advertisement()`, `server_advertises_channel()`

**Implementation Notes:**
- `struct ChathistoryAd` added to `m_chathistory.c:1360-1372`
- Global `server_ads[MAX_AD_SERVERS]` array (indexed by server numeric)
- Helper functions:
  - `has_chathistory_advertisement(server)` - checks if server stores history
  - `server_retention_days(server)` - returns retention policy
  - `clear_server_ad(server)` - clears on SQUIT (hooked in `s_misc.c:exit_one_client`)
- CH A parser handles subtypes: S (storage), R (retention), F/+/- (channel sync - future)
- Declarations added to `handlers.h`

**Verification:** Servers parse CH A messages without behavior change.

### Phase 2: Advertisement Sending âœ… COMPLETE

1. On server link (BURST complete): Send `CH A S <retention>`
2. On BURST: Send `CH A F` with all channels in history DB (deferred to Layer 1)
3. On new history write: Send `CH A +` if channel wasn't advertised (deferred to Layer 1)

**Implementation Notes:**
- `m_endburst.c:ms_end_of_burst()` - added CH A S sending after END_OF_BURST_ACK
- âœ… Now correctly checks `FEAT_CHATHISTORY_STORE` (updated in Phase 0)
- Added `ircd_features.h` include for `feature_bool()` and `feature_int()`
- CH A R on REHASH deferred as refinement (REHASH is rare, BURST provides correct value)

**Verification:** Servers send CH A messages. Monitor with P10 logging.

### Phase 3: Advertisement-Based Routing âœ… COMPLETE

1. Modify query routing to check advertisements
2. Only query servers that have storage + relevant channels
3. Skip servers that explicitly don't advertise the target

**Implementation Notes:**
- Added `server_retention_covers(server, query_time)` helper function
- Added `count_storage_servers(query_time)` to count only CH A S servers
- Modified `start_fed_query()` to:
  - Parse timestamp from reference for retention filtering
  - Only count/query servers with `has_chathistory_advertisement()`
  - Apply retention window filtering via `server_retention_covers()`
- Modified `ms_chathistory()` CH Q propagation to:
  - Extract timestamp from S2S reference format (T<timestamp>)
  - Filter propagation to storage servers only
  - Apply same advertisement + retention checks
- No backward compatibility needed (new feature, no legacy servers)

**Filtering Logic:**
- Server has CH A S â†’ query/propagate
- Server has no CH A S â†’ skip (doesn't store history)
- Server retention doesn't cover query timestamp â†’ skip

**Declaration added to `handlers.h`:**
- `extern int server_retention_covers(struct Client*, time_t);`

**Verification:** Federation queries only go to relevant servers.

### Phase 4: Write Forwarding (CH W) - Approach B

**Prerequisites:** Decide between Approach A and B. This phase implements Approach B.

**Protocol Design (accounting for multiline/batching):**

P10 line limit is 512 bytes. After headers (~100 bytes), ~400 bytes are safe for content.
Multiline messages can be up to 4096 bytes (FEAT_MULTILINE_MAX_BYTES).
Solution: Use chunked base64 encoding (same pattern as CH B responses).

```
CH W - Plain text write forward (content â‰¤ 400 bytes, no newlines)
  <server> CH W <target> <msgid> <ts> <sender> <account> <type> :<content>
  Example: AX CH W #channel abc123 1736856000.123 alice!a@host alice P :Hello!

CH WB - Base64 encoded write forward (for large/multiline content)
  First/full (parc=9 or 10):
    <server> CH WB <target> <msgid> <ts> <sender> <account> <type> [+] :<b64>
  Continuation (parc=5 or 6):
    <server> CH WB <target> <msgid> [+] :<b64>
  + marker means more chunks coming; no + means final chunk

Parameters:
  <target>  - Channel name (e.g., #channel)
  <msgid>   - Message ID for deduplication
  <ts>      - Unix timestamp with milliseconds (e.g., 1736856000.123)
  <sender>  - Full sender mask (nick!user@host)
  <account> - Sender's account name, or * if not logged in
  <type>    - Message type: P=PRIVMSG, N=NOTICE, T=TAGMSG
```

**Implementation steps:**

1. Add `FEAT_CHATHISTORY_WRITE_FORWARD` feature flag
2. Add `history_has_msgid()` function for deduplication
3. Add `CH W` and `CH WB` parsers in `ms_chathistory()`
4. Add `send_ch_write()` function (mirrors `send_ch_response()` chunking logic)
5. Add `forward_history_write()` function to find nearest storage server
6. Modify `store_channel_history()` to call `forward_history_write()` when STORE is disabled
7. STORE servers receive CH W/WB and decide what to store:
   - Registered channels (+r): Always store
   - Unregistered with local users: Store
   - Unregistered without local users: Ignore
8. Implement msgid-based deduplication at STORE server

**Verification:** Messages to channels in storage gaps are forwarded and stored.

**Implementation Notes (Complete):**

Files modified:
- `include/ircd_features.h` - Added `FEAT_CHATHISTORY_WRITE_FORWARD`, `FEAT_CHATHISTORY_STORE_REGISTERED`
- `ircd/ircd_features.c` - Added feature flag definitions (both default TRUE)
- `include/history.h` - Added `history_has_msgid()` declaration
- `ircd/history.c` - Added `history_has_msgid()` implementation (checks msgid index in LMDB)
- `include/handlers.h` - Added `forward_history_write()` declaration
- `ircd/m_chathistory.c`:
  - Added `WriteChunkEntry` structure and chunk management functions
  - Added `process_write_forward()` - decides whether to store based on channel registration and local users
  - Added `send_ch_write()` - sends CH W or CH WB with chunking (mirrors `send_ch_response()`)
  - Added `forward_history_write()` - finds nearest storage server and forwards
  - Added `CH W` handler in `ms_chathistory()` for plain text writes
  - Added `CH WB` handler in `ms_chathistory()` for base64 chunked writes
- `ircd/ircd_relay.c`:
  - Added `#include "handlers.h"`
  - Modified `store_channel_history()` to call `forward_history_write()` when STORE disabled

Key implementation details:
- Chunking uses same `CH_CHUNK_B64_SIZE` (400 bytes) as CH B responses
- Deduplication via `history_has_msgid()` before storing
- Storage decision: registered (+r) OR has local users â†’ store; otherwise ignore
- Write forwarding finds first storage server in `cli_serv(&me)->down` list

### Phase 5: Registered Channel Storage Policy

**Status:** âœ… Implemented as part of Phase 4

The registered channel storage logic was implemented directly in `process_write_forward()`:
- Added `FEAT_CHATHISTORY_STORE_REGISTERED` feature flag (default TRUE)
- CH W/WB handler checks `(chptr->mode.mode & MODE_REGISTERED)`
- Registered channels (+r) are always stored regardless of local user presence
- Unregistered channels only stored if they have local users

**Note:** This phase only enables storage on STORE servers that *receive* messages. Phase 4 (CH W) is required to ensure messages reach STORE servers in the first place.

**Verification:** Registered channels are stored on STORE servers that receive the messages.

### Phase 6: Storage Management âœ… COMPLETE

1. Add `history_db_utilization()` function
2. Implement background eviction with watermarks
3. Add storage state machine (NORMAL â†’ WARNING â†’ CRITICAL â†’ SUSPENDED)
4. Add eviction to STATS output

**Implementation Notes:**

Files modified:
- `include/ircd_features.h` - Added feature flags:
  - `FEAT_CHATHISTORY_HIGH_WATERMARK` (default 85)
  - `FEAT_CHATHISTORY_LOW_WATERMARK` (default 75)
  - `FEAT_CHATHISTORY_MAINTENANCE_INTERVAL` (default 300 seconds)
  - `FEAT_CHATHISTORY_EVICT_BATCH_SIZE` (default 1000)
- `ircd/ircd_features.c` - Added feature flag definitions
- `include/history.h`:
  - Added `enum HistoryStorageState` (NORMAL, WARNING, CRITICAL, SUSPENDED)
  - Added declarations: `history_db_utilization()`, `history_storage_state()`,
    `history_evict_to_target()`, `history_maintenance_tick()`, `history_last_eviction()`
- `ircd/history.c`:
  - Added `#include "ircd_features.h"` for feature flag access
  - Added static tracking: `last_eviction_count`, `last_eviction_time`, `last_maintenance_time`
  - Implemented `history_db_utilization()` using LMDB `mdb_env_info()` and `mdb_env_stat()`
  - Implemented `history_storage_state()` with thresholds: 85%=WARNING, 95%=CRITICAL, 99%=SUSPENDED
  - Implemented `history_evict_to_target()` - evicts oldest messages in batches
  - Implemented `history_maintenance_tick()` - checks interval and triggers eviction
  - Updated `history_report_stats()` to show storage size, utilization, state, watermarks, last eviction
  - Added stub implementations for non-LMDB builds
- `ircd/ircd.c` - Added `history_maintenance_tick()` call to `history_purge_callback()`

Key implementation details:
- Utilization calculated as: `(last_pgno + 1) * page_size / mapsize * 100`
- Eviction processes messages in batches (default 1000) to avoid long transactions
- Maintenance self-throttles via `last_maintenance_time` check
- STATS H now shows: size, utilization%, state, retention, watermarks, last eviction

**Verification:** Storage stays within limits, graceful degradation works.

### Phase 7: Refinements (Future)

1. Add time ranges for smarter BEFORE/AFTER routing
2. Consider bloom filter for very large channel sets
3. Add STATS command for advertisement state
4. Handle advertisement expiry

---

## Configuration Reference

### Core Feature Flags (Phase 0 Decoupling)

```
/* CAP advertisement - enables CHATHISTORY command handling */
"CAP_draft_chathistory" = "TRUE";    /* Advertise draft/chathistory to clients */

/* Storage - separate from CAP (NEW in Phase 0) */
"CHATHISTORY_STORE" = "TRUE";        /* Actually store messages locally */
                                     /* FALSE = relay-only server */
```

**Server Role Matrix:**

| CAP_draft_chathistory | CHATHISTORY_STORE | Role |
|-----------------------|-------------------|------|
| TRUE | TRUE | Storage server (default) |
| TRUE | FALSE | Relay server (forwards to STORE) |
| FALSE | * | No chathistory participation |

### Existing Feature Flags

```
"CHATHISTORY_RETENTION" = "7";       /* Days to keep history (0 = unlimited) */
"CHATHISTORY_DB" = "/path/to/db";    /* LMDB database path */
"CHATHISTORY_MAX" = "100";           /* Max messages per query */
```

### New: Registered Channel Storage

```
/* Store ALL messages for registered channels, regardless of local users */
"CHATHISTORY_STORE_REGISTERED" = "TRUE";    /* Default: enabled */
```

This eliminates storage gaps for registered channels by ensuring every STORE server stores messages for channels with +r mode, even if no local users are present.

### New: Write Forwarding (Approach B)

```
/* Write forwarding - non-STORE servers forward to STORE servers */
"CHATHISTORY_WRITE_FORWARD" = "TRUE";    /* Enable write forwarding */
"CHATHISTORY_FORWARD_TYPES" = "PN";      /* Forward PRIVMSG and NOTICE only */
```

**CHATHISTORY_FORWARD_TYPES options:** `P` (PRIVMSG), `N` (NOTICE), `T` (TAGMSG), `*` (all)

**Note:** Non-STORE servers forward ALL channel messages. The STORE server decides what to store based on registration status and local user presence. This simplifies non-STORE logic - they don't need to know channel state.

### New: Storage Management

```
/* Storage limits */
"CHATHISTORY_DB_MAXSIZE" = "1073741824";    /* 1GB - LMDB mapsize */
"CHATHISTORY_HIGH_WATERMARK" = "0.85";      /* Start eviction at 85% */
"CHATHISTORY_LOW_WATERMARK" = "0.75";       /* Evict down to 75% */
"CHATHISTORY_MAINTENANCE_INTERVAL" = "300"; /* Check every 5 minutes */

/* Eviction behavior */
"CHATHISTORY_EVICT_EVENTS_FIRST" = "TRUE";  /* Prioritize event eviction */
"CHATHISTORY_EVENT_RETENTION_FACTOR" = "0.5"; /* Events expire at 50% of retention */
"CHATHISTORY_EVICT_BATCH_SIZE" = "1000";    /* Messages per eviction pass */
```

---

## Security Considerations

### Nick Reuse Privacy Attack

DM history stored using nick pairs creates a vulnerability:

1. Alice (unregistered) has private DM conversation with Bob
2. Alice disconnects
3. Mallory connects using nick "alice"
4. Mallory queries `CHATHISTORY * bob`
5. Mallory receives Alice's private conversation

### Mitigation: Consent System

Use `FEAT_CHATHISTORY_PRIVATE_CONSENT`:

| Mode | Behavior | Security |
|------|----------|----------|
| 0 (global) | DM history for everyone | **UNSAFE for unregistered** |
| 1 (single-party) | Either party opts in | **UNSAFE for unregistered** |
| 2 (mutual) | Both parties must opt in | Acceptable with warning |

**Recommendations:**
1. Default to mutual consent (mode 2)
2. Display impersonation warning for unregistered users at opt-in
3. **Warn registered users when DMing unregistered users** - their messages could be exposed to future nick impersonators
4. Encourage registration for secure DM history
5. Consider disabling DM history for unregistered entirely (`FEAT_CHATHISTORY_PRIVATE_REQUIRE_ACCOUNT`)

### Security by User Type

| Threat | Registered User | Unregistered User |
|--------|-----------------|-------------------|
| Impersonation | Protected by account binding | Requires mutual consent + warning |
| Future nick reuse | History tied to account | Risk persists |
| DM with unregistered | **Exposed if other party's nick reused** | Same risk as above |
| Account compromise | Attacker gets all history | N/A |

---

## Edge Cases

### Server Restarts
- Loses in-memory advertisement tracking
- On reconnect, sends fresh `CH A F` from history DB
- Other servers replace old advertisement

### History Expiry
- Channel may become empty after expiry
- Do NOT send `CH A -` (unsafe race with new writes)
- Eventually send fresh `CH A F` with accurate state

### Netsplit
- Advertisements diverge during split
- On reconnect, re-burst establishes correct state
- May query servers without history during split (acceptable)

### Channel Name Case Sensitivity
- IRC channels are case-insensitive (#foo = #FOO)
- Advertisement set uses lowercase normalized names
- Query routing lowercases before lookup

---

## Alternatives Considered

### Negative Caching
Cache "server X returned empty" and skip future queries.

**Rejected:** History state changes constantly; would need TTL and invalidation; may miss history.

### Query-Time Channel Presence Check
Use BURST channel membership to infer history presence.

**Rejected:** History exists for destroyed channels; channels can exist without history.

### Central History Registry
Designate one server as "history authority."

**Rejected:** Single point of failure; doesn't fit IRC's distributed model.

### Designated Archive Server
All servers forward to central archive.

**Rejected:** Bandwidth concentration; doesn't scale; single point of failure.

---

## Open Questions

1. **Bloom filter viability**: At what channel count does bloom filter become better than explicit list?

2. **Advertisement lifetime**: Should advertisements expire after N hours without update?

3. **Compression**: For large channel lists, should `CH A F` use zstd compression?

4. **Time range advertisement**: Add oldest/newest timestamp per channel (`CH A T`)?

5. **Per-channel storage limits**: Should there be a max messages per channel?

6. **Msgid propagation verification**: Confirm that msgids generated at origin are preserved through:
   - P10 server-to-server relay (tags in P token?)
   - All relay paths (direct, via hub, etc.)
   - Need to audit `ircd_relay.c` and P10 message format to verify tags flow correctly

---

## Success Criteria

### Advertisement (CH A)
1. **Correctness**: Never miss history that exists (no false negatives)
2. **Latency reduction**: Queries complete faster by targeting relevant servers
3. **Traffic reduction**: Servers without history don't receive queries
4. **Scale**: Works with 10+ servers and 50,000+ channels
5. **Backward compatible**: Works with servers that don't implement CH A

### Registered Channel Storage
1. **Complete coverage**: All registered channels stored on STORE servers that receive them
2. **User expectation met**: "Registered = persistent" mental model
3. **Simple storage decision**: Single `IsRegisteredChannel()` check on STORE server

### Write Forwarding (Approach B)
1. **Gap elimination**: Messages from non-STORE servers reach STORE servers
2. **No latency impact**: Forwarding is async, doesn't block delivery
3. **Deduplication works**: No duplicate messages in results (msgid-based)
4. **Graceful degradation**: If storage unreachable, messages still delivered
5. **Simple forwarding logic**: Non-STORE servers forward everything, STORE servers decide

### Storage Management
1. **No data loss**: Eviction only removes expired/oldest messages
2. **Predictable performance**: No write stalls during eviction
3. **Visibility**: Operators can monitor storage health
4. **Retention honored**: Messages within retention preserved when possible

---

## Recommendation: Approach A vs. B

### Summary Comparison

| Factor | Approach A (Core Relay) | Approach B (Write Forwarding) |
|--------|------------------------|------------------------------|
| **Changes to core relay** | Yes - `sendcmdto_channel_*()` | No |
| **New P10 command** | No | Yes (CH W) |
| **Deduplication needed** | Less (natural relay dedup) | Yes (msgid-based) |
| **Hub participation** | Every hub must participate | Non-STORE servers only |
| **Rollout risk** | Higher (delivery path) | Lower (parallel path) |
| **Failure impact** | Could affect delivery | Only affects storage |
| **Implementation complexity** | Medium | Medium-High |
| **Testing complexity** | High (delivery edge cases) | Medium (new path) |

### Recommendation

**Prefer Approach B (Write Forwarding)** for these reasons:

1. **Isolation of concerns:** Storage failures never affect message delivery
2. **Safer rollout:** Can be enabled per-server without network-wide coordination
3. **Clearer semantics:** CH W explicitly means "store this" vs. implicit routing
4. **Hub simplification:** Hubs don't need to track which servers store

**Consider Approach A only if:**
- Network topology is very simple (few servers, all directly connected)
- The additional traffic of CH W is a significant concern
- Team has deep familiarity with the relay code and confidence in modifications

### Implementation Note

With Approach B, the **only modification** to core relay code is adding the `maybe_forward_history()` hook after message delivery. The hook is fire-and-forget (async) and doesn't block delivery.

```c
// In relay_channel_message() after successful delivery
if (feature_bool(FEAT_CHATHISTORY_WRITE_FORWARD))
  maybe_forward_history(chptr, sptr, msgid, text);
```

---

## Notes

This is a design exploration document. Implementation should not begin until:
1. Design is reviewed and approved
2. Edge cases are thoroughly analyzed
3. Backward compatibility strategy is confirmed
4. Test plan for multi-server scenarios is developed
5. Security considerations are addressed in implementation
